import json
import pandas as pd
from typing import Dict, Any, Optional
import tempfile
import gradio as gr


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _df_to_records(df: Optional[pd.DataFrame]) -> list[dict]:
    """Safely convert a DataFrame to a list-of-dicts records representation.

    Returns an empty list if *df* is ``None`` or empty.
    """
    if df is not None and isinstance(df, pd.DataFrame) and not df.empty:
        return df.to_dict(orient="records")
    return []


def _records_to_df(records: list[dict]) -> pd.DataFrame:
    """Convert a list of dicts into a DataFrame – returns an empty DF for
    falsy/empty input so callers can always rely on getting a DataFrame.
    """
    return pd.DataFrame(records or [])


# ---------------------------------------------------------------------------
# Public helpers (save / load)
# ---------------------------------------------------------------------------


def save_state(
    world_conditions: str,
    world_epochs: int,
    world_df: Optional[pd.DataFrame],
    country_conditions: str,
    country_df: Optional[pd.DataFrame],
    city_conditions: str,
    city_df: Optional[pd.DataFrame],
    family_conditions: str,
    family_generations: int,
    family_df: Optional[pd.DataFrame],
    character_conditions: str,
    character_chapters: int,
    character_df: Optional[pd.DataFrame],
) -> str:
    """Serialize the current dashboard state to JSON.

    All *DataFrame* arguments are optional – ``None`` or an *empty* frame will
    be stored as an empty list in the resulting JSON. This keeps the file
    compact and makes the layout tolerant to future field additions/removals.
    """

    state = {
        "world": {
            "conditions": world_conditions,
            "epochs": world_epochs,
            "data": _df_to_records(world_df),
        },
        "country": {
            "conditions": country_conditions,
            "data": _df_to_records(country_df),
        },
        "city": {
            "conditions": city_conditions,
            "data": _df_to_records(city_df),
        },
        "family": {
            "conditions": family_conditions,
            "generations": family_generations,
            "data": _df_to_records(family_df),
        },
        "character": {
            "conditions": character_conditions,
            "chapters": character_chapters,
            "data": _df_to_records(character_df),
        },
    }

    return json.dumps(state)


def load_state(state_json: str) -> Dict[str, Any]:
    """Deserialize *state_json* generated by :pyfunc:`save_state`.

    The loader is *forgiving*: if a section or field is missing (e.g. because
    the file was produced by an older version of the dashboard), a sensible
    default value is returned instead of raising *KeyError* – making the
    feature fully backwards-compatible.
    """

    raw_state = json.loads(state_json or "{}")

    world = raw_state.get("world", {})
    country = raw_state.get("country", {})
    city = raw_state.get("city", {})
    family = raw_state.get("family", {})
    character = raw_state.get("character", {})
    return {
        "world_conditions": world.get("conditions", ""),
        "world_epochs": world.get("epochs", 0),
        "world_df": _records_to_df(world.get("data", [])),

        "country_conditions": country.get("conditions", ""),
        "country_df": _records_to_df(country.get("data", [])),

        "city_conditions": city.get("conditions", ""),
        "city_df": _records_to_df(city.get("data", [])),

        "family_conditions": family.get("conditions", ""),
        "family_generations": family.get("generations", 0),
        "family_df": _records_to_df(family.get("data", [])),

        "character_conditions": character.get("conditions", ""),
        "character_chapters": character.get("chapters", 0),
        "character_df": _records_to_df(character.get("data", [])),

        "character_sheet_name": character.get("name", ""),
        "character_sheet_final_conditions": character.get("final_conditions", ""),
    }


def save_state_to_file(state_json: str, filename: str) -> None:
    """Save state to a .save file."""
    with open(filename, 'w') as f:
        f.write(state_json)


def load_state_from_file(filename: str) -> str:
    """Load state from a .save file."""
    with open(filename, 'r') as f:
        return f.read()


# ---------------------------------------------------------------------------
# Gradio helper handlers (used directly by the dashboard)
# ---------------------------------------------------------------------------


def save_state_handler(
    world_conditions: str,
    world_epochs: int,
    world_df: pd.DataFrame,
    country_conditions: str,
    country_df: pd.DataFrame,
    city_conditions: str,
    city_df: pd.DataFrame,
    family_conditions: str,
    family_generations: int,
    family_df: pd.DataFrame,
    character_conditions: str,
    character_chapters: int,
    character_df: pd.DataFrame,
    character_sheet_name: str,
    character_sheet_final_conditions: str,
    biological_sex: str,
    gender_identity: str,
    sexuality: str,
    hexaco_honesty: int,
    hexaco_emotionality: int,
    hexaco_extraversion: int,
    hexaco_agreeableness: int,
    hexaco_conscientiousness: int,
    hexaco_openness: int,
    family_systems_inheritance_df: pd.DataFrame,
    character_grand_narratives_df: pd.DataFrame,
    pursued_identities_df: pd.DataFrame,
    avoided_identities_df: pd.DataFrame,
    values_df: pd.DataFrame,
    behavioral_repertoire_df: pd.DataFrame,
    language_and_vocabulary_df: pd.DataFrame,
) -> str:
    """Aggregate all dashboard fields, write a *.save* file and return its path.

    This wraps :pyfunc:`save_state` for the historical data while adding the
    new *character_sheet* block required by the updated dashboard. It returns
    the filename Gradio should offer for download.
    """

    # Base (history) section – reuse existing helper for consistency
    base_json = save_state(
        world_conditions,
        world_epochs,
        world_df,
        country_conditions,
        country_df,
        city_conditions,
        city_df,
        family_conditions,
        family_generations,
        family_df,
        character_conditions,
        character_chapters,
        character_df,
    )

    state_obj = json.loads(base_json)

    # Extended character-sheet section
    state_obj["character_sheet"] = {
        "name": character_sheet_name,
        "final_conditions": character_sheet_final_conditions,
        "biological_sex": biological_sex,
        "gender_identity": gender_identity,
        "sexuality": sexuality,
        "hexaco_traits": {
            "honesty_humility": hexaco_honesty,
            "emotionality": hexaco_emotionality,
            "extraversion": hexaco_extraversion,
            "agreeableness": hexaco_agreeableness,
            "conscientiousness": hexaco_conscientiousness,
            "openness": hexaco_openness,
        },
        "family_systems_inheritance": _df_to_records(family_systems_inheritance_df),
        "grand_narratives": _df_to_records(character_grand_narratives_df),
        "pursued_identities": _df_to_records(pursued_identities_df),
        "avoided_identities": _df_to_records(avoided_identities_df),
        "values": _df_to_records(values_df),
        "behavioral_repertoire": _df_to_records(behavioral_repertoire_df),
        "language_and_vocabulary": _df_to_records(language_and_vocabulary_df),
    }

    # Write to a uniquely-named temporary file
    json_payload = json.dumps(state_obj, ensure_ascii=False)
    tmp = tempfile.NamedTemporaryFile(delete=False, prefix="loregen_", suffix=".save")
    tmp.write(json_payload.encode("utf-8"))
    tmp.flush()
    tmp.close()

    return tmp.name


def load_state_handler(file_obj):
    """Gradio click handler – loads a *.save* file.

    Returns a list of values corresponding to the dashboard's *outputs* list.
    If a field is missing, :pyfunc:`gr.skip` is returned so the corresponding
    component remains unchanged.
    """

    # Total expected outputs (must match dashboard wiring)
    total_outputs = 29

    if file_obj is None or file_obj.name is None:
        return [gr.skip()] * total_outputs

    try:
        state_json = load_state_from_file(file_obj.name)
        base = load_state(state_json)  # tolerant base loader
        raw_state = json.loads(state_json)
        char_sheet = raw_state.get("character_sheet", {})

        # Build ordered output list
        out = [
            base["world_conditions"],
            base["world_epochs"],
            base["world_df"],
            base["country_conditions"],
            base["country_df"],
            base["city_conditions"],
            base["city_df"],
            base["family_conditions"],
            base["family_generations"],
            base["family_df"],
            base["character_conditions"],
            base["character_chapters"],
            base["character_df"],
        ]

        # Helper to fetch or skip
        def g(key, default=gr.skip()):
            return char_sheet.get(key, default)

        def gt(trait):
            return char_sheet.get("hexaco_traits", {}).get(trait, gr.skip())

        out.extend([
            g("name"),
            g("final_conditions"),
            g("biological_sex"),
            g("gender_identity"),
            g("sexuality"),
            gt("honesty_humility"),
            gt("emotionality"),
            gt("extraversion"),
            gt("agreeableness"),
            gt("conscientiousness"),
            gt("openness"),
            _records_to_df(g("family_systems_inheritance", []))
            if "family_systems_inheritance" in char_sheet
            else gr.skip(),
            _records_to_df(g("grand_narratives", []))
            if "grand_narratives" in char_sheet
            else gr.skip(),
            _records_to_df(g("pursued_identities", []))
            if "pursued_identities" in char_sheet
            else gr.skip(),
            _records_to_df(g("avoided_identities", []))
            if "avoided_identities" in char_sheet
            else gr.skip(),
            _records_to_df(g("values", [])) if "values" in char_sheet else gr.skip(),
            _records_to_df(g("behavioral_repertoire", []))
            if "behavioral_repertoire" in char_sheet
            else gr.skip(),
            _records_to_df(g("language_and_vocabulary", []))
            if "language_and_vocabulary" in char_sheet
            else gr.skip(),
        ])

        # Ensure correct length
        if len(out) < total_outputs:
            out.extend([gr.skip()] * (total_outputs - len(out)))
        return out

    except Exception:
        # Any error – return skip for all outputs so UI stays untouched
        return [gr.skip()] * total_outputs
